{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These below definitions helps to \n",
    "\n",
    "### 1) SummaryWriter \n",
    "\n",
    "### 2 ) save 2D array as file, \n",
    "\n",
    "### 3) reshapes 3D data to new dimension padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "mpl.use(\"agg\")\n",
    "\n",
    "def mpl_image_grid(images):\n",
    "    # Create a figure to contain the plot.\n",
    "    n = min(images.shape[0], 16) \n",
    "    rows = 4\n",
    "    cols = (n // 4) + (1 if (n % 4) != 0 else 0)\n",
    "    figure = plt.figure(figsize=(2*rows, 2*cols))\n",
    "    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n",
    "    for i in range(n):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(cols, rows, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        if images.shape[1] == 3:\n",
    "           \n",
    "            vol = images[i].detach().numpy()\n",
    "            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n",
    "                            for y in range(vol.shape[2])] \\\n",
    "                            for x in range(vol.shape[1])]\n",
    "            plt.imshow(img)\n",
    "        else: \n",
    "            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n",
    "\n",
    "    return figure\n",
    "\n",
    "def log_to_tensorboard(writer, loss, data, target, prediction_softmax, prediction, counter):\n",
    "\n",
    "    writer.add_scalar(\"Loss\",\\\n",
    "                    loss, counter)\n",
    "    writer.add_figure(\"Image Data\",\\\n",
    "        mpl_image_grid(data.float().cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Mask\",\\\n",
    "        mpl_image_grid(target.float().cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Probability map\",\\\n",
    "        mpl_image_grid(prediction_softmax.cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Prediction\",\\\n",
    "        mpl_image_grid(torch.argmax(prediction.cpu(), dim=1, keepdim=True)), global_step=counter)\n",
    "\n",
    "def save_numpy_as_image(arr, path):\n",
    "\n",
    "    plt.imshow(arr, cmap=\"gray\") \n",
    "    plt.savefig(path)\n",
    "\n",
    "def med_reshape(image, new_shape):\n",
    "\n",
    "    reshaped_image = np.zeros(new_shape)\n",
    "\n",
    "    reshaped_image[:image.shape[0],:image.shape[1],:image.shape[2]]=image\n",
    "\n",
    "    return reshaped_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    This function loads our dataset form disk into memory, reshaping output to common size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "\n",
    "\n",
    "def LoadHippocampusData(root_dir, y_shape, z_shape):\n",
    "\n",
    "\n",
    "    image_dir = os.path.join('images')\n",
    "    label_dir = os.path.join('labels')\n",
    "\n",
    "    images = [f for f in listdir(image_dir) if (\n",
    "        isfile(join(image_dir, f)) and f[0] != \".\")]\n",
    "\n",
    "    out = []\n",
    "    for f in images:\n",
    "\n",
    "\n",
    "        image, _ = load(os.path.join(image_dir, f))\n",
    "        label, _ = load(os.path.join(label_dir, f))\n",
    "        \n",
    "        image=(image-image.min())/(image.max()-image.min())\n",
    "\n",
    "        image = med_reshape(image, new_shape=(image.shape[0], y_shape, z_shape))\n",
    "        label = med_reshape(label, new_shape=(label.shape[0], y_shape, z_shape)).astype(int)\n",
    "\n",
    "        out.append({\"image\": image, \"seg\": label, \"filename\": f})\n",
    "\n",
    "    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module for Pytorch dataset representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SlicesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.slices = []\n",
    "\n",
    "        for i, d in enumerate(data):\n",
    "            for j in range(d[\"image\"].shape[0]):\n",
    "                self.slices.append((i, j))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slc = self.slices[idx]\n",
    "        sample = dict()\n",
    "        sample[\"id\"] = idx\n",
    "\n",
    "        img=self.data[slc[0]]['image'][slc[1]]\n",
    "        seg=self.data[slc[0]]['seg'][slc[1]][None,:]\n",
    "        sample['image']=torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "        sample['seg']=torch.from_numpy(seg).long().cuda()\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contains various functions for computing statistics over 3D volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Dice3d(a, b):\n",
    "    if len(a.shape) != 3 or len(b.shape) != 3:\n",
    "        raise Exception(f\"Expecting 3 dimensional inputs, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise Exception(f\"Expecting inputs of the same shape, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    \n",
    "    a[a>0]=1\n",
    "    b[b>0]=1\n",
    "    intersection = np.sum(a*b)\n",
    "    volumes = np.sum(a) + np.sum(b)\n",
    "    if volumes == 0:\n",
    "        return -1\n",
    "\n",
    "    return 2.*float(intersection) / float(volumes)\n",
    "\n",
    "def Jaccard3d(a, b):\n",
    "    if len(a.shape) != 3 or len(b.shape) != 3:\n",
    "        raise Exception(f\"Expecting 3 dimensional inputs, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise Exception(f\"Expecting inputs of the same shape, got {a.shape} and {b.shape}\")\n",
    "\n",
    "\n",
    "    a[a>0]=1\n",
    "    b[b>0]=1\n",
    "    intersection = np.sum(a*b)\n",
    "    union = np.sum(a) + np.sum(b)-intersection\n",
    "\n",
    "    if union == 0:\n",
    "        return -1\n",
    "    return float(intersection) / float(union)\n",
    "\n",
    "\n",
    "def sensitivity(gt,pred):\n",
    "    # Sens = TP/(TP+FN)\n",
    "    tp = np.sum(gt[gt==pred])\n",
    "    fn = np.sum(gt[gt!=pred])\n",
    "\n",
    "    if fn+tp == 0:\n",
    "        return -1\n",
    "\n",
    "    return (tp)/(fn+tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recursive implementation of Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=3, in_channels=1, initial_filter_size=64, kernel_size=3, num_downs=4, norm_layer=nn.InstanceNorm2d):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-1), out_channels=initial_filter_size * 2 ** num_downs,\n",
    "                                             num_classes=num_classes, kernel_size=kernel_size, norm_layer=norm_layer, innermost=True)\n",
    "        for i in range(1, num_downs):\n",
    "            unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-(i+1)),\n",
    "                                                 out_channels=initial_filter_size * 2 ** (num_downs-i),\n",
    "                                                 num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(in_channels=in_channels, out_channels=initial_filter_size,\n",
    "                                             num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer,\n",
    "                                             outermost=True)\n",
    "\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, in_channels=None, out_channels=None, num_classes=1, kernel_size=3,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.InstanceNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        # downconv\n",
    "        pool = nn.MaxPool2d(2, stride=2)\n",
    "        conv1 = self.contract(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
    "        conv2 = self.contract(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
    "\n",
    "        # upconv\n",
    "        conv3 = self.expand(in_channels=out_channels*2, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        conv4 = self.expand(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
    "\n",
    "        if outermost:\n",
    "            final = nn.Conv2d(out_channels, num_classes, kernel_size=1)\n",
    "            down = [conv1, conv2]\n",
    "            up = [conv3, conv4, final]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels,\n",
    "                                        kernel_size=2, stride=2)\n",
    "            model = [pool, conv1, conv2, upconv]\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels, kernel_size=2, stride=2)\n",
    "\n",
    "            down = [pool, conv1, conv2]\n",
    "            up = [conv3, conv4, upconv]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    @staticmethod\n",
    "    def contract(in_channels, out_channels, kernel_size=3, norm_layer=nn.InstanceNorm2d):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
    "            norm_layer(out_channels),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def expand(in_channels, out_channels, kernel_size=3):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop(layer, target_width, target_height):\n",
    "        batch_size, n_channels, layer_width, layer_height = layer.size()\n",
    "        xy1 = (layer_width - target_width) // 2\n",
    "        xy2 = (layer_height - target_height) // 2\n",
    "        return layer[:, :, xy1:(xy1 + target_width), xy2:(xy2 + target_height)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            crop = self.center_crop(self.model(x), x.size()[2], x.size()[3])\n",
    "            return torch.cat([x, crop], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contains class that runs inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class UNetInferenceAgent:\n",
    "    def __init__(self, parameter_file_path='', model=None, device=\"cpu\", patch_size=64):\n",
    "\n",
    "        self.model = model\n",
    "        self.patch_size = patch_size\n",
    "        self.device = device\n",
    "\n",
    "        if model is None:\n",
    "            self.model = UNet(num_classes=3)\n",
    "\n",
    "        if parameter_file_path:\n",
    "            self.model.load_state_dict(torch.load(parameter_file_path, map_location=self.device))\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    def single_volume_inference_unpadded(self, volume):\n",
    "        patch_size = 64\n",
    "        volume=(volume-volume.min())/(volume.max()-volume.min())\n",
    "        volume = med_reshape(volume, new_shape=(volume.shape[0], patch_size, patch_size))\n",
    "        \n",
    "        masks=np.zeros(volume.shape)\n",
    "        for slice_idx in range(masks.shape[0]):\n",
    "            # normalize the image\n",
    "            slice_0 = volume[slice_idx,:,:]\n",
    "            #slice0_norm = (slice0-slice0.min())/(slice0.max()-slice0.min())\n",
    "            data=torch.from_numpy(slice_0).unsqueeze(0).unsqueeze(0).float().to(self.device)\n",
    "            pred=self.model(data)\n",
    "            pred=np.squeeze(pred.cpu().detach())\n",
    "            pred=pred.argmax(axis=0)\n",
    "            masks[slice_idx,:,:]=pred\n",
    "        return masks\n",
    "\n",
    "    def single_volume_inference(self, volume):\n",
    "        self.model.eval()\n",
    "\n",
    "        slices = []\n",
    "\n",
    "        \n",
    "        masks=np.zeros(volume.shape)\n",
    "        for slice_idx in range(masks.shape[0]):\n",
    "            slice_0 = volume[slice_idx,:,:]\n",
    "            data=torch.from_numpy(slice_0).unsqueeze(0).unsqueeze(0).float().to(self.device)\n",
    "            pred=self.model(data)\n",
    "            pred=np.squeeze(pred.cpu().detach())\n",
    "            pred=pred.argmax(axis=0)\n",
    "            masks[slice_idx,:,:]=pred\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This module represents a UNet experiment and contains a class that handles the experiment lifecycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class UNetExperiment:\n",
    "    def __init__(self, config, split, dataset):\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.split = split\n",
    "        self._time_start = \"\"\n",
    "        self._time_end = \"\"\n",
    "        self.epoch = 0\n",
    "        self.name = config.name\n",
    "\n",
    "        dirname = f'{time.strftime(\"%Y-%m-%d_%H%M\", time.gmtime())}_{self.name}'\n",
    "        self.out_dir = os.path.join(config.test_results_dir, dirname)\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "        self.train_loader = DataLoader(SlicesDataset(dataset[split[\"train\"]]),\n",
    "                batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "        self.val_loader = DataLoader(SlicesDataset(dataset[split[\"val\"]]),\n",
    "                batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        self.test_data = dataset[split[\"test\"]]\n",
    "\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"WARNING: No CUDA device is found. This may take significantly longer!\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = UNet(num_classes=3)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
    "\n",
    " \n",
    "        \n",
    "        self.tensorboard_train_writer = SummaryWriter(comment=\"_train\")\n",
    "        self.tensorboard_val_writer = SummaryWriter(comment=\"_val\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        This method is executed once per epoch and takes \n",
    "        care of model weight update cycle\n",
    "        \"\"\"\n",
    "        print(f\"Training epoch {self.epoch}...\")\n",
    "        self.model.train()\n",
    "\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            data = batch['image'].to(self.device, dtype=torch.float)\n",
    "            target = batch['seg'].to(self.device)\n",
    "\n",
    "            prediction = self.model(data)\n",
    "\n",
    "            prediction_softmax = F.softmax(prediction, dim=1)\n",
    "\n",
    "            loss = self.loss_function(prediction, target[:, 0, :, :])\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if (i % 10) == 0:\n",
    "                print(f\"\\nEpoch: {self.epoch} Train loss: {loss}, {100*(i+1)/len(self.train_loader):.1f}% complete\")\n",
    "\n",
    "                counter = 100*self.epoch + 100*(i/len(self.train_loader))\n",
    "\n",
    "                log_to_tensorboard(\n",
    "                    self.tensorboard_train_writer,\n",
    "                    loss,\n",
    "                    data,\n",
    "                    target,\n",
    "                    prediction_softmax,\n",
    "                    prediction,\n",
    "                    counter)\n",
    "\n",
    "            print(\".\", end='')\n",
    "\n",
    "        print(\"\\nTraining complete\")\n",
    "\n",
    "    def validate(self):\n",
    "        print(f\"Validating epoch {self.epoch}...\")\n",
    "\n",
    "        # Turn off gradient accumulation by switching model to \"eval\" mode\n",
    "        self.model.eval()\n",
    "        loss_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_loader):\n",
    "                \n",
    "                data = batch['image'].to(self.device, dtype=torch.float)\n",
    "                target = batch['seg'].to(self.device)\n",
    "                prediction = self.model(data)\n",
    "\n",
    "                prediction_softmax = F.softmax(prediction, dim=1)\n",
    "\n",
    "                loss = self.loss_function(prediction, target[:, 0, :, :])\n",
    "                \n",
    "\n",
    "                print(f\"Batch {i}. Data shape {data.shape} Loss {loss}\")\n",
    "\n",
    "                loss_list.append(loss.item())\n",
    "\n",
    "        self.scheduler.step(np.mean(loss_list))\n",
    "\n",
    "        log_to_tensorboard(\n",
    "            self.tensorboard_val_writer,\n",
    "            np.mean(loss_list),\n",
    "            data,\n",
    "            target,\n",
    "            prediction_softmax, \n",
    "            prediction,\n",
    "            (self.epoch+1) * 100) ### ttttt\n",
    "        print(f\"Validation complete\")\n",
    "\n",
    "    def save_model_parameters(self):\n",
    "        \"\"\"\n",
    "        Saves model parameters to a file in results directory\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.out_dir, \"model.pth\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load_model_parameters(self, path=''):\n",
    "        \"\"\"\n",
    "        Loads model parameters from a supplied path or a\n",
    "        results directory\n",
    "        \"\"\"\n",
    "        if not path:\n",
    "            model_path = os.path.join(self.out_dir, \"model.pth\")\n",
    "        else:\n",
    "            model_path = path\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        else:\n",
    "            raise Exception(f\"Could not find path {model_path}\")\n",
    "\n",
    "    def run_test(self):\n",
    "        print(\"Testing...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        inference_agent = UNetInferenceAgent(model=self.model, device=self.device)\n",
    "\n",
    "        out_dict = {}\n",
    "        out_dict[\"volume_stats\"] = []\n",
    "        dc_list = []\n",
    "        jc_list = []\n",
    "        sen_list =[]\n",
    "\n",
    "        # for every in test set\n",
    "        for i, x in enumerate(self.test_data):\n",
    "            pred_label = inference_agent.single_volume_inference(x[\"image\"])\n",
    "\n",
    "\n",
    "            dc = Dice3d(pred_label, x[\"seg\"])\n",
    "            jc = Jaccard3d(pred_label, x[\"seg\"])\n",
    "            sen = sensitivity(x[\"seg\"],pred_label)\n",
    "            dc_list.append(dc)\n",
    "            jc_list.append(jc)\n",
    "            sen_list.append(sen)\n",
    "\n",
    "\n",
    "            out_dict[\"volume_stats\"].append({\n",
    "                \"filename\": x['filename'],\n",
    "                \"dice\": dc,\n",
    "                \"jaccard\": jc,\n",
    "                \"sensitivity\": sen\n",
    "                })\n",
    "            print(f\"{x['filename']} Dice {dc:.4f}. {100*(i+1)/len(self.test_data):.2f}% complete\")\n",
    "\n",
    "        out_dict[\"overall\"] = {\n",
    "            \"mean_dice\": np.mean(dc_list),\n",
    "            \"mean_jaccard\": np.mean(jc_list),\n",
    "            \"mean_sensitivity\": np.mean(sen_list)\n",
    "            }\n",
    "\n",
    "        print(\"\\nTesting complete.\")\n",
    "        return out_dict\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Kicks off train cycle and writes model parameter file at the end\n",
    "        \"\"\"\n",
    "        self._time_start = time.time()\n",
    "\n",
    "        print(\"Experiment started.\")\n",
    "\n",
    "        # Iterate over epochs\n",
    "        for self.epoch in range(self.n_epochs):\n",
    "            self.train()\n",
    "            self.validate()\n",
    "\n",
    "        # save model for inferencing\n",
    "        self.save_model_parameters()\n",
    "\n",
    "        self._time_end = time.time()\n",
    "        print(f\"Run complete. Total time: {time.strftime('%H:%M:%S', time.gmtime(self._time_end - self._time_start))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains code that will kick off training and testing processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Holds configuration parameters\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Basic_unet\"\n",
    "        self.root_dir = r\"out/\"\n",
    "        self.n_epochs = 2\n",
    "        self.learning_rate = .0002\n",
    "        self.batch_size = 8\n",
    "        self.patch_size = 64\n",
    "        self.test_results_dir = \"result/\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    c = Config()\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    data = LoadHippocampusData(c.root_dir, y_shape = c.patch_size, z_shape = c.patch_size)\n",
    "\n",
    "\n",
    "\n",
    "    keys = range(len(data))\n",
    "\n",
    "\n",
    "    split = dict()\n",
    "\n",
    "    \n",
    "    split['train'],split['test'] = train_test_split(keys, test_size =0.25, random_state=40)\n",
    "    split['train'],split['val'] = train_test_split(split['train'], test_size =0.25, random_state=40)\n",
    "    print('Split Done')\n",
    "    \n",
    "\n",
    "    \n",
    "    exp = UNetExperiment(c, split, data)\n",
    "\n",
    "    \n",
    "    exp.run()\n",
    "\n",
    "\n",
    "    results_json = exp.run_test()\n",
    "\n",
    "    results_json[\"config\"] = vars(c)\n",
    "\n",
    "    with open(os.path.join(exp.out_dir, \"results.json\"), 'w') as out_file:\n",
    "        json.dump(results_json, out_file, indent=2, separators=(',', ': '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
